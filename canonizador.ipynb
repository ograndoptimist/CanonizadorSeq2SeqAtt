{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Preparação do Tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Tokenizador do Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./canonizador_tokenizer-vocab.json\",\n",
    "    \"./canonizador_tokenizer-merges.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Tokenizador do Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./output_canonizador_tokenizer-vocab.json\",\n",
    "    \"./output_canonizador_tokenizer-merges.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_token =  input_tokenizer.get_vocab()['<pad>']\n",
    "start_token = output_tokenizer.get_vocab()['<start>']\n",
    "end_token = output_tokenizer.get_vocab()['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Ingestão de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/final_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impressora hp laser', 'estetoscopio', 'painel para tv quarto']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1:3, 'query_string'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_for_rnn(x, null):\n",
    "    lengths = torch.sum(x != null, dim=1).long()\n",
    "    sorted_lengths, sorted_idx = torch.sort(lengths, dim=0, descending=True)\n",
    "    sorted_lengths = sorted_lengths.data.tolist() \n",
    "    inverse_sorted_idx = torch.LongTensor(sorted_idx.shape).fill_(null)\n",
    "    for i, v in enumerate(sorted_idx):\n",
    "        inverse_sorted_idx[v.data] = i\n",
    "\n",
    "    return x[sorted_idx], sorted_lengths, inverse_sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        H = hidden.repeat(seq_len, 1, 1).transpose(0,1)\n",
    "        attn_energies = self.score(H, encoder_outputs) # B*1*T\n",
    "        return F.softmax(attn_energies, dim=2)\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        energy = F.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2))) # [B*T*2H]->[B*T*H]\n",
    "        energy = energy.transpose(2,1) # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]\n",
    "        energy = torch.bmm(v, energy) # [B*1*T]\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Preparação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.data.index = range(len(data))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        input_data = self.data.loc[idx, 'query_string']\n",
    "        output_data = self.data.loc[idx, 'output']\n",
    "        \n",
    "        sample = {'input': input_data, 'output': output_data}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NLPDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAtt(nn.Module):\n",
    "    def __init__(self,\n",
    "      null_token=0,\n",
    "      start_token=1,\n",
    "      end_token=2,\n",
    "      encoder_vocab_size=100,\n",
    "      decoder_vocab_size=100,\n",
    "      wordvec_dim=300,\n",
    "      hidden_dim=256,\n",
    "      rnn_num_layers=2,\n",
    "      rnn_dropout=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder_embed = nn.Embedding(encoder_vocab_size, wordvec_dim)\n",
    "        self.encoder_rnn = nn.LSTM(wordvec_dim, hidden_dim, rnn_num_layers,\n",
    "                                   dropout=rnn_dropout, batch_first=True)\n",
    "        self.decoder_embed = nn.Embedding(decoder_vocab_size, wordvec_dim)\n",
    "        self.decoder_rnn = nn.LSTM(wordvec_dim + hidden_dim, hidden_dim, rnn_num_layers,\n",
    "                                   dropout=rnn_dropout, batch_first=True)\n",
    "        self.decoder_linear = nn.Linear(hidden_dim, decoder_vocab_size)\n",
    "        self.decoder_attn = Attn(hidden_dim)\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.NULL = null_token\n",
    "        self.START = start_token\n",
    "        self.END = end_token\n",
    "        self.multinomial_outputs = None\n",
    "\n",
    "    def expand_encoder_vocab(self, token_to_idx, word2vec=None, std=0.01):\n",
    "        expand_embedding_vocab(self.encoder_embed, token_to_idx,\n",
    "                               word2vec=word2vec, std=std)\n",
    "\n",
    "    def get_dims(self, x=None, y=None):\n",
    "        V_in = self.encoder_embed.num_embeddings\n",
    "        V_out = self.decoder_embed.num_embeddings\n",
    "        D = self.encoder_embed.embedding_dim\n",
    "        H = self.encoder_rnn.hidden_size\n",
    "        L = self.encoder_rnn.num_layers\n",
    "\n",
    "        N = x.size(0) if x is not None else None\n",
    "        N = y.size(0) if N is None and y is not None else N\n",
    "        T_in = x.size(1) if x is not None else None\n",
    "        T_out = y.size(1) if y is not None else None\n",
    "        return V_in, V_out, D, H, L, N, T_in, T_out\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x, x_lengths, inverse_index = sort_for_rnn(x, null=self.NULL)\n",
    "        embed = self.encoder_embed(x)\n",
    "        packed = pack_padded_sequence(embed, x_lengths, batch_first=True)\n",
    "        out_packed, hidden = self.encoder_rnn(packed)\n",
    "        out, _ = pad_packed_sequence(out_packed, batch_first=True)\n",
    "\n",
    "        out = out[inverse_index]\n",
    "        hidden = [h[:,inverse_index] for h in hidden]\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def decoder(self, word_inputs, encoder_outputs, prev_hidden):\n",
    "        hn, cn = prev_hidden\n",
    "        word_embedded = self.decoder_embed(word_inputs).unsqueeze(1) # batch x 1 x embed\n",
    "\n",
    "        attn_weights = self.decoder_attn(encoder_outputs, hn[-1])\n",
    "        context = attn_weights.bmm(encoder_outputs) # batch x 1 x hidden\n",
    "\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.decoder_rnn(rnn_input, prev_hidden)\n",
    "\n",
    "        output = output.squeeze(1) # batch x hidden\n",
    "        output = self.decoder_linear(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def compute_loss(self, output_logprobs, y):\n",
    "        self.multinomial_outputs = None\n",
    "        V_in, V_out, D, H, L, N, T_in, T_out = self.get_dims(y=y)\n",
    "        mask = y.data != self.NULL\n",
    "        y_mask = Variable(torch.Tensor(N, T_out).fill_(0).type_as(mask))\n",
    "        y_mask[:, 1:] = mask[:, 1:]\n",
    "        y_masked = y[y_mask]\n",
    "        out_mask = Variable(torch.Tensor(N, T_out).fill_(0).type_as(mask))\n",
    "        out_mask[:, :-1] = mask[:, 1:]\n",
    "        out_mask = out_mask.view(N, T_out, 1).expand(N, T_out, V_out)\n",
    "        out_masked = output_logprobs[out_mask].view(-1, V_out)\n",
    "        loss = F.cross_entropy(out_masked, y_masked)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        max_target_length = y.size(1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x)\n",
    "        decoder_inputs = y\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        for t in range(max_target_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(\n",
    "                decoder_inputs[:,t], encoder_outputs, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_out)\n",
    "\n",
    "        decoder_outputs = torch.stack(decoder_outputs, dim=1)\n",
    "        loss = self.compute_loss(decoder_outputs, y)\n",
    "        return loss\n",
    "\n",
    "    def sample(self, x, max_length=50):\n",
    "        self.multinomial_outputs = None\n",
    "        assert x.size(0) == 1, \"Sampling minibatches not implemented\"\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        sampled_output = [self.START]\n",
    "        for t in range(max_length):\n",
    "            decoder_input = Variable(torch.cuda.LongTensor([sampled_output[-1]]))\n",
    "            decoder_out, decoder_hidden = self.decoder(\n",
    "                decoder_input, encoder_outputs, decoder_hidden)\n",
    "            _, argmax = decoder_out.data.max(1)\n",
    "            output = argmax[0]\n",
    "            sampled_output.append(output)\n",
    "            if output == self.END:\n",
    "                break\n",
    "\n",
    "        return sampled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Preparação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2SeqAtt(null_token=null_token, start_token=start_token, end_token=end_token,\n",
    "                     encoder_vocab_size=len(input_tokenizer.get_vocab()),\n",
    "                     decoder_vocab_size=len(input_tokenizer.get_vocab()), \n",
    "                     wordvec_dim=48, hidden_dim=64, rnn_num_layers=1,\n",
    "                     rnn_dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq2seq.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor(sequences):\n",
    "    num = len(sequences)\n",
    "    max_len = max([s.shape[0] for s in sequences])\n",
    "    out_dims = (num, max_len, *sequences[0].shape[1:])\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(1)   \n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        out_tensor[i, :length] = tensor\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    seq2seq.train()\n",
    "    for batch in dataloader:\n",
    "        input_data = batch['input']\n",
    "        output_data = batch['output']\n",
    "        \n",
    "        x = [torch.tensor(row.ids) for row in input_tokenizer.encode_batch(input_data)]\n",
    "        y = [torch.tensor(row.ids) for row in output_tokenizer.encode_batch(output_data)]\n",
    "        \n",
    "        x = padding_tensor(x)\n",
    "        y = padding_tensor(y)\n",
    "        \n",
    "        loss = seq2seq(x, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
